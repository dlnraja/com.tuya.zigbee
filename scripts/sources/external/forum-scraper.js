#!/usr/bin/env node
'use strict';

'use strict';

const https = require('https');
const fs = require('fs');
const path = require('path');

const ROOT = process.cwd();
const SOURCES_DIR = path.join(ROOT, 'scripts', 'sources');
const EXTERNAL_DIR = path.join(SOURCES_DIR, 'external');
const FORUMS_DIR = path.join(EXTERNAL_DIR, 'forums');
const REPORTS_DIR = path.join(EXTERNAL_DIR, 'reports');

// Sources de forums Ã  analyser
const FORUM_SOURCES = {
    'homey-community': {
        url: 'https://community.homey.app',
        sections: [
            't/tuya/',
            't/zigbee/',
            't/drivers/',
            't/development/'
        ],
        keywords: ['tuya', 'zigbee', 'driver', 'device', 'compatibility']
    },
    'tuya-developer': {
        url: 'https://developer.tuya.com',
        sections: [
            'en/docs/iot/',
            'en/docs/zigbee/',
            'en/docs/device-management/'
        ],
        keywords: ['zigbee', 'protocol', 'cluster', 'device', 'fingerprint']
    },
    'zigbee-alliance': {
        url: 'https://zigbeealliance.org',
        sections: [
            'developers/',
            'specifications/',
            'certification/'
        ],
        keywords: ['tuya', 'device', 'certification', 'specification']
    }
};

// Fonction pour faire une requÃªte HTTPS
function makeRequest(url) {
    return new Promise((resolve, reject) => {
        const req = https.get(url, (res) => {
            let data = '';
            res.on('data', chunk => data += chunk);
            res.on('end', () => resolve(data));
        });
        req.on('error', reject);
        req.setTimeout(15000, () => req.destroy());
    });
}

// Fonction pour extraire les informations d'une page de forum
function extractForumInfo(html, keywords) {
    const content = html.toLowerCase();
    const foundKeywords = keywords.filter(keyword => content.includes(keyword.toLowerCase()));
    
    // Extraire les titres de sujets
    const topicMatches = html.match(/<h[1-6][^>]*>([^<]+)<\/h[1-6]>/gi) || [];
    const topics = topicMatches.map(match => match.replace(/<[^>]+>/g, '').trim()).slice(0, 10);
    
    // Extraire les liens
    const linkMatches = html.match(/<a[^>]+href = "([^"]+)"[^>]*>([^<]+)<\/a>/gi) || [];
    const links = linkMatches.map(match => {
        const hrefMatch = match.match(/href = "([^"]+)"/);
        const textMatch = match.match(/>([^<]+)</);
        return {
            href: hrefMatch ? hrefMatch[1] : '',
            text: textMatch ? textMatch[1].trim() : ''
        };
    }).slice(0, 20);
    
    // Extraire les dates
    const dateMatches = html.match(/\d{1,2}\/\d{1,2}\/\d{4}|\d{4}-\d{2}-\d{2}/g) || [];
    const dates = [...new Set(dateMatches)].slice(0, 5);
    
    return {
        foundKeywords,
        topics: topics.filter(t => t.length > 10),
        links: links.filter(l => l.href && l.text.length > 5),
        dates: dates,
        contentLength: html.length
    };
}

// Fonction pour scraper un forum
async function scrapeForum(forumName, forumConfig) {
    console.log(`ğŸ” Scraping du forum: ${forumName}`);
    
    const results = {
        forum: forumName,
        url: forumConfig.url,
        sections: {},
        summary: {
            totalKeywordsFound: 0,
            totalTopics: 0,
            totalLinks: 0,
            totalErrors: 0
        }
    };
    
    for (const section of forumConfig.sections) {
        try {
            console.log(`  ğŸ“‚ Section: ${section}`);
            const fullUrl = `${forumConfig.url}/${section}`;
            
            const html = await makeRequest(fullUrl);
            const extractedInfo = extractForumInfo(html, forumConfig.keywords);
            
            results.sections[section] = {
                url: fullUrl,
                ...extractedInfo,
                scrapedAt: new Date().toISOString()
            };
            
            results.summary.totalKeywordsFound += extractedInfo.foundKeywords.length;
            results.summary.totalTopics += extractedInfo.topics.length;
            results.summary.totalLinks += extractedInfo.links.length;
            
            // Pause pour Ã©viter d'Ãªtre bloquÃ©
            await new Promise(resolve => setTimeout(resolve, 2000));
            
        } catch (error) {
            console.log(`    âŒ Erreur pour la section ${section}:`, error.message);
            results.sections[section] = {
                url: `${forumConfig.url}/${section}`,
                error: error.message,
                scrapedAt: new Date().toISOString()
            };
            results.summary.totalErrors++;
        }
    }
    
    return results;
}

// Fonction pour scraper tous les forums
async function scrapeAllForums() {
    console.log('ğŸš€ DÃ©but du scraping des forums...');
    
    const results = {};
    const startTime = Date.now();
    
    for (const [forumName, forumConfig] of Object.entries(FORUM_SOURCES)) {
        console.log(`\nğŸ“Š Traitement du forum: ${forumName}`);
        results[forumName] = await scrapeForum(forumName, forumConfig);
    }
    
    const endTime = Date.now();
    const duration = endTime - startTime;
    
    // Sauvegarder les rÃ©sultats
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const reportPath = path.join(REPORTS_DIR, `forum-scraping-${timestamp}.json`);
    
    const report = {
        timestamp: new Date().toISOString(),
        duration: `${duration}ms`,
        totalForums: Object.keys(results).length,
        results,
        summary: {
            totalKeywordsFound: Object.values(results).reduce((sum, forum) => 
                sum + forum.summary.totalKeywordsFound, 0),
            totalTopics: Object.values(results).reduce((sum, forum) => 
                sum + forum.summary.totalTopics, 0),
            totalLinks: Object.values(results).reduce((sum, forum) => 
                sum + forum.summary.totalLinks, 0),
            totalErrors: Object.values(results).reduce((sum, forum) => 
                sum + forum.summary.totalErrors, 0)
        }
    };
    
    fs.writeFileSync(reportPath, JSON.stringify(report, null, 2));
    console.log(`\nâœ… Rapport des forums sauvegardÃ©: ${reportPath}`);
    
    return report;
}

// Fonction principale
async function main() {
    try {
        // CrÃ©er les dossiers nÃ©cessaires
        [SOURCES_DIR, EXTERNAL_DIR, FORUMS_DIR, REPORTS_DIR].forEach(dir => {
            if (!fs.existsSync(dir)) {
                fs.mkdirSync(dir, { recursive: true });
            }
        });
        
        console.log('ğŸ“ Dossiers crÃ©Ã©s avec succÃ¨s');
        
        // Lancer le scraping
        const report = await scrapeAllForums();
        
        console.log('\nğŸ‰ Scraping des forums terminÃ© avec succÃ¨s !');
        console.log(`ğŸ“Š RÃ©sumÃ©: ${report.summary.totalForums} forums analysÃ©s`);
        console.log(`ğŸ”‘ Mots-clÃ©s trouvÃ©s: ${report.summary.totalKeywordsFound}`);
        console.log(`ğŸ“ Sujets trouvÃ©s: ${report.summary.totalTopics}`);
        console.log(`ğŸ”— Liens trouvÃ©s: ${report.summary.totalLinks}`);
        console.log(`âŒ Erreurs: ${report.summary.totalErrors}`);
        console.log(`â±ï¸ DurÃ©e: ${report.duration}`);
        
    } catch (error) {
        console.error('âŒ Erreur lors du scraping des forums:', error);
        process.exit(1);
    }
}

if (require.main === module) {
    main();
}

module.exports = { scrapeAllForums, scrapeForum };
